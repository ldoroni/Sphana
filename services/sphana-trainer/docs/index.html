<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sphana Trainer Documentation</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
  </head>
  <body>
    <!-- Header -->
    <header class="header">
        <div class="header-content">
            <div class="header-left">
                <h1 class="logo">Sphana Trainer</h1>
                <p class="tagline">Neural Model Training CLI for NRDB</p>
      </div>
            <div class="header-right">
                <div class="search-wrapper">
                    <input type="search" id="search" placeholder="Search documentation..." aria-label="Search" autocomplete="off">
                    <div class="search-results" id="searchResults"></div>
      </div>
      </div>
        </div>
        <!-- Dark mode toggle will be added by JavaScript -->
    </header>

    <!-- Reading Progress Bar (added by JavaScript) -->
    
    <!-- Main Layout -->
    <div class="layout">
        <!-- Sidebar -->
      <aside class="sidebar">
            <nav class="nav">
                <div class="nav-section">
                    <h3 class="nav-title">Getting Started</h3>
                    <a href="#overview" class="nav-link">Overview</a>
                    <a href="#installation" class="nav-link">Installation</a>
                    <a href="#quick-start" class="nav-link">Quick Start</a>
                </div>

                <div class="nav-section">
                    <h3 class="nav-title">Core Concepts</h3>
                    <a href="#architecture" class="nav-link">Architecture</a>
                    <a href="#components" class="nav-link">Model Components</a>
                    <a href="#workflow" class="nav-link">Training Workflow</a>
                </div>

                <div class="nav-section">
                    <h3 class="nav-title">User Guide</h3>
                    <a href="#data-preparation" class="nav-link">Data Preparation</a>
                    <a href="#training" class="nav-link">Training Models</a>
                    <a href="#export-package" class="nav-link">Export & Package</a>
                    <a href="#workflows" class="nav-link">Automated Workflows</a>
                </div>

                <div class="nav-section">
                    <h3 class="nav-title">Reference</h3>
                    <a href="#cli-reference" class="nav-link">CLI Commands</a>
                    <a href="#configuration" class="nav-link">Configuration</a>
                    <a href="#api" class="nav-link">Python API</a>
                </div>

                <div class="nav-section">
                    <h3 class="nav-title">Advanced</h3>
                    <a href="#distributed" class="nav-link">Distributed Training</a>
                    <a href="#mlflow" class="nav-link">MLflow Integration</a>
                    <a href="#optimization" class="nav-link">Optimization</a>
                </div>
        </nav>
      </aside>

        <!-- Main Content -->
        <main class="main-content">
            <!-- Overview -->
            <section id="overview" class="section">
                <h2>Overview</h2>
                <div class="intro-box">
                    <p class="lead">Sphana Trainer is a Python CLI tool for training and exporting the neural models that power the <strong>Sphana Neural RAG Database (NRDB)</strong>.</p>
                </div>

                <h3>What It Does</h3>
                <div class="feature-grid">
                    <div class="feature-card">
                        <div class="feature-icon">
                            <svg width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="color: var(--color-primary);">
                                <path d="M3 3h18v18H3z"/><path d="M3 9h18M9 21V9"/>
                            </svg>
                        </div>
                        <h4>Data Processing</h4>
                        <p>Ingest documents, extract relations, and build training datasets</p>
                    </div>
                    <div class="feature-card">
                        <div class="feature-icon">
                            <svg width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="color: var(--color-primary);">
                                <circle cx="12" cy="12" r="10"/><path d="M12 8v8m-4-4h8"/>
                            </svg>
                        </div>
                        <h4>Model Training</h4>
                        <p>Train embedding, relation extraction, and GNN ranking models</p>
                    </div>
                    <div class="feature-card">
                        <div class="feature-icon">
                            <svg width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="color: var(--color-primary);">
                                <rect x="3" y="3" width="18" height="18" rx="2"/><path d="M3 9h18M9 21V9"/>
                            </svg>
                        </div>
                        <h4>Export & Package</h4>
                        <p>Export to ONNX with INT8 quantization for production deployment</p>
                    </div>
                    <div class="feature-card">
                        <div class="feature-icon">
                            <svg width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="color: var(--color-primary);">
                                <path d="M13 2L3 14h9l-1 8 10-12h-9l1-8z"/>
                            </svg>
                        </div>
                        <h4>Workflow Automation</h4>
                        <p>End-to-end pipelines with state tracking and MLflow logging</p>
                    </div>
                </div>

                <h3>Key Features</h3>
                <ul class="features-list">
                    <li><strong>Three Neural Components:</strong> Embedding encoder, relation extraction classifier, and GNN reasoner</li>
                    <li><strong>ONNX Export:</strong> Production-ready models with INT8 quantization for low-latency inference</li>
                    <li><strong>Flexible Data Pipeline:</strong> Support for spaCy, Stanza, and simple parsers</li>
                    <li><strong>Distributed Training:</strong> Multi-GPU training with automatic device management</li>
                    <li><strong>MLflow Integration:</strong> Experiment tracking, metrics logging, and artifact management</li>
                    <li><strong>Workflow Automation:</strong> Complete pipelines from ingestion to packaging</li>
        </ul>

                <div class="info-box" style="padding-left: 3.5rem;">
                    <strong>Note:</strong> This documentation covers the Python training CLI only. For the complete NRDB architecture including the .NET gRPC service, see the design documents in <code>design/</code>.
        </div>
      </section>

            <!-- Installation -->
            <section id="installation" class="section">
                <h2>Installation</h2>
                
                <p>Set up the Sphana Trainer CLI on your development machine. This is a one-time setup required before training models.</p>

                <h3>System Requirements</h3>
                <div class="info-box">
                    <strong>Required:</strong>
                    <ul>
                        <li><strong>Python:</strong> 3.11 or higher</li>
                        <li><strong>OS:</strong> Windows with PowerShell</li>
                        <li><strong>RAM:</strong> 8GB minimum (16GB+ recommended for production training)</li>
                        <li><strong>Storage:</strong> ~5GB for dependencies, models, and artifacts</li>
                    </ul>
                    <strong>Optional (but recommended):</strong>
                    <ul>
                        <li><strong>CUDA:</strong> 12.8+ with compatible NVIDIA GPU for faster training</li>
                        <li><strong>RAM:</strong> 32GB for large-scale production datasets</li>
                    </ul>
                </div>

                <h3>Installation Steps</h3>
        <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">PowerShell - Run in order</span>
                        <button class="copy-btn" data-target="setup-code">Copy</button>
                    </div>
                    <pre><code id="setup-code"># 1. Navigate to project directory
cd services/sphana-trainer

# 2. Set Python path (required for module imports)
$env:PYTHONPATH="src"

# 3. Create and activate virtual environment
python -m venv .venv
.\.venv\Scripts\activate

# 4. Upgrade pip and install dependencies
python -m pip install --upgrade pip
pip install -r requirements.txt</code></pre>
        </div>

                <div class="info-box">
                    <strong>What gets installed?</strong>
                    <ul>
                        <li><strong>PyTorch:</strong> Deep learning framework (CUDA 12.8 version if GPU detected)</li>
                        <li><strong>Transformers:</strong> Hugging Face library for pretrained models</li>
                        <li><strong>ONNX:</strong> Model export and quantization tools</li>
                        <li><strong>MLflow:</strong> Experiment tracking (optional but recommended)</li>
                        <li><strong>Typer & Rich:</strong> CLI framework with beautiful output</li>
                        <li><strong>spaCy/Stanza:</strong> Optional NLP parsers (install separately if needed)</li>
                    </ul>
                    Total installation size: ~2-3GB depending on CUDA support.
                </div>

                <h3>Verify Installation</h3>
                <p>Confirm everything is working correctly:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Test CLI</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli --help</code></pre>
                </div>

                <div class="success-box">
                    <strong>‚úÖ Success!</strong> If you see the CLI help message listing all available commands, installation is complete.
                    <br><br>
                    <strong>Next step:</strong> Continue to the <a href="#quick-start" style="color: inherit; text-decoration: underline;">Quick Start Guide</a> to train your first models.
                </div>

                <div class="warning-box">
                    <strong>Troubleshooting:</strong>
                    <ul>
                        <li><strong>ModuleNotFoundError:</strong> Ensure <code>$env:PYTHONPATH="src"</code> is set in your current session</li>
                        <li><strong>CUDA not available:</strong> Training will use CPU (slower but functional). Install CUDA 12.8+ for GPU support</li>
                        <li><strong>Pip install fails:</strong> Try upgrading pip: <code>python -m pip install --upgrade pip setuptools wheel</code></li>
                        <li><strong>Out of disk space:</strong> Free up at least 5GB before installation</li>
                    </ul>
                </div>
      </section>

            <!-- Quick Start -->
            <section id="quick-start" class="section">
                <h2>Quick Start</h2>
                
                <p>This guide walks you through the complete process of training, exporting, and packaging neural models for the Sphana NRDB. Complete the <a href="#installation">Installation</a> section first, then follow these steps to go from raw data to production-ready ONNX models.</p>

                <h3>Step 1: Obtain Training Data</h3>
                <p>You have two options for getting training data:</p>

                <h4>Option A: Use Built-in Sample Data (Fastest)</h4>
                <p>The repository includes small sample datasets in <code>src/tests/data/</code> for quick testing. These are automatically used by the base configurations.</p>
                <div class="info-box">
                    <strong>Sample datasets:</strong>
                    <ul>
                        <li><code>src/tests/data/embedding/train.jsonl</code> - 50+ query-context pairs</li>
                        <li><code>src/tests/data/relation/train.jsonl</code> - 40+ relation examples</li>
                        <li><code>src/tests/data/graphs/train.jsonl</code> - 30+ graph structures for GNN</li>
                    </ul>
                    These datasets are suitable for smoke testing but won't produce production-quality models.
                </div>

                <h4>Option B: Build Custom Dataset from Documents (Production)</h4>
                <p>For production models, ingest your own documents or download Wikipedia data:</p>

                <div class="info-box">
                    <strong>üì• What this downloads:</strong>
                    <ul>
                        <li><strong>Two Modes Available:</strong>
                            <ul style="margin-top: 0.5rem;">
                                <li><strong>Summaries (default):</strong> 1-3 paragraphs per article - fast, good for quick testing</li>
                                <li><strong>Full Content (<code>--full-content</code>):</strong> Complete article text - comprehensive, better for production training</li>
                            </ul>
                        </li>
                        <li><strong>Required Input:</strong> You must provide titles via <code>--title</code> or <code>--titles-file</code></li>
                        <li><strong>Output Format:</strong> JSONL file with id, title, text, and source fields</li>
                    </ul>
                </div>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Download summaries (fast, inline titles)</span>
                        <button class="copy-btn" data-target="download-wiki-summaries">Copy</button>
                    </div>
                    <pre><code id="download-wiki-summaries">python -m sphana_trainer.cli dataset-download-wiki `
    --output target\data\docs.jsonl `
    --title "Machine learning" `
    --title "Deep learning" `
    --title "Natural language processing" `
    --title "Neural network" `
    --full-content</code></pre>
                </div>
                    
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Download full content (comprehensive, from file)</span>
                        <button class="copy-btn" data-target="download-wiki-full">Copy</button>
                    </div>
                    <pre><code id="download-wiki-full">python -m sphana_trainer.cli dataset-download-wiki `
    --output target\data\docs.jsonl `
    --titles-file samples\ai-ml-wiki-titles.medium.txt `
    --full-content `
    --limit 10000</code></pre>
                </div>
                    
                <div class="success-box">
                    <strong>üí° Which mode should you use?</strong>
                    <ul>
                        <li><strong>Summaries (default):</strong> Perfect for initial experimentation, quick iteration, and testing pipeline configurations. Downloads 10-100x faster.</li>
                        <li><strong>Full content (<code>--full-content</code>):</strong> Recommended for production training when you need comprehensive, detailed text for better model quality. Takes longer but provides richer training data.</li>
                    </ul>
                </div>

                <div class="info-box">
                    <strong>üìã Example output format:</strong> Each line is a JSON document:
                    <pre style="margin-top: 0.5rem;"><code>{
  "id": 233488,
  "title": "Machine learning",
  "text": "Machine learning (ML) is a field of study...",
  "source": "wikipedia"
}</code></pre>
                </div>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Ingest and process documents</span>
                        <button class="copy-btn" data-target="ingest-docs">Copy</button>
                    </div>
                    <pre><code id="ingest-docs"># Run ingestion pipeline (extracts entities, relations, builds knowledge graph)
python -m sphana_trainer.cli ingest --config configs\ingest\wiki.yaml

# Build training datasets from ingestion outputs
python -m sphana_trainer.cli dataset-build-from-ingest `
    target\ingest `
    --output-dir target\datasets `
    --min-confidence 0.3 `
    --val-ratio 0.2</code></pre>
                </div>

                <div class="info-box">
                    <strong>What's happening during ingestion?</strong>
                    <ol>
                        <li><strong>Parsing:</strong> Documents are tokenized and analyzed (simple/spaCy/Stanza parsers)</li>
                        <li><strong>Entity Extraction:</strong> Named entities are identified and typed</li>
                        <li><strong>Relation Extraction:</strong> Relationships between entities are discovered</li>
                        <li><strong>Knowledge Graph Construction:</strong> Triples (subject, predicate, object) are created</li>
                        <li><strong>Dataset Splitting:</strong> Data is split into training/validation sets for each model type</li>
        </ol>
                    Output: Three ready-to-train JSONL datasets (embedding, relation, GNN).
        </div>

                <h3>Step 2: Configure Training Parameters</h3>
                <p>Review and adjust configuration files in <code>configs/</code> based on your needs:</p>

        <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">configs/embedding/base.yaml (example adjustments)</span>
                    </div>
                    <pre><code>version: "0.1.0"
model_name: "sentence-transformers/all-MiniLM-L6-v2"  # Change model if needed
batch_size: 32              # Reduce if GPU memory is limited (e.g., 8 or 16)
learning_rate: 2e-5         # Adjust for your dataset size
epochs: 3                   # Increase for better convergence (5-10 for production)
precision: "fp16"           # Use "fp32" on CPU, "bf16" on modern GPUs
max_length: 128             # Token limit per input

# Dataset paths (update if using custom data)
train_file: "src/tests/data/embedding/train.jsonl"      # Change to custom path
validation_file: "src/tests/data/embedding/val.jsonl"   # Optional but recommended

# Quality gates
metric_threshold: 0.75      # Minimum cosine similarity to export model

# MLflow tracking (optional)
log_to_mlflow: true
mlflow_experiment: "embedding-training"</code></pre>
        </div>

                <div class="warning-box">
                    <strong>Important Configuration Notes:</strong>
                    <ul>
                        <li><strong>Dataset paths:</strong> If you built custom datasets in Step 1, update <code>train_file</code> and <code>validation_file</code> to point to <code>target/datasets/wiki/embedding/train.jsonl</code></li>
                        <li><strong>GPU memory:</strong> If training fails with OOM errors, reduce <code>batch_size</code> or increase <code>gradient_accumulation</code></li>
                        <li><strong>CPU training:</strong> Set <code>precision: "fp32"</code> (fp16/bf16 require GPU)</li>
                        <li><strong>Epochs:</strong> Sample data needs 2-3 epochs; production data may need 5-10+</li>
                        <li><strong>Validation:</strong> Always provide a validation set to monitor overfitting and enable early stopping</li>
        </ul>
                </div>

                <h3>Step 3: Train All Models</h3>
                <p>Train the three neural components required by the NRDB:</p>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Train all components sequentially</span>
                        <button class="copy-btn" data-target="train-all">Copy</button>
        </div>
                    <pre><code id="train-all"># 1. Embedding encoder (dense semantic vectors)
python -m sphana_trainer.cli train embedding --config configs\embedding\base.yaml

# 2. Relation extraction classifier (entity-centric relationships)
python -m sphana_trainer.cli train relation --config configs\relation\base.yaml

# 3. GNN ranker (graph neural network for re-ranking)
python -m sphana_trainer.cli train gnn --config configs\gnn\base.yaml</code></pre>
                </div>

                <div class="info-box">
                    <strong>Training outputs:</strong> Each command creates:
                    <ul>
                        <li><code>target/artifacts/&lt;component&gt;/&lt;version&gt;/</code> - Model checkpoint, ONNX export, metadata</li>
                        <li><code>target/artifacts/&lt;component&gt;/latest.json</code> - Pointer to the most recent version</li>
                        <li><code>target/logs/trainer.log</code> - Detailed training logs</li>
                        <li><code>target/mlruns/</code> - MLflow experiment data (if enabled)</li>
        </ul>
                    Training time: ~2-5 minutes per model on sample data (GPU), 10-30 minutes on CPU.
                </div>

                <h3>Step 4: Export to ONNX Format</h3>
                <p>Convert trained PyTorch models to ONNX with INT8 quantization for production deployment:</p>

        <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Export and quantize models</span>
                        <button class="copy-btn" data-target="export-code">Copy</button>
        </div>
                    <pre><code id="export-code">python -m sphana_trainer.cli export --config configs\export\base.yaml</code></pre>
          </div>

                <div class="info-box">
                    <strong>What happens during export?</strong>
                    <ol>
                        <li><strong>Validation:</strong> Checks that all required components (embedding, relation, GNN) are trained</li>
                        <li><strong>ONNX Conversion:</strong> PyTorch models ‚Üí ONNX format with dynamic axes</li>
                        <li><strong>Quantization:</strong> Applies INT8 quantization for 4x faster inference with minimal accuracy loss</li>
                        <li><strong>Parity Check:</strong> Verifies ONNX outputs match PyTorch (within 1% tolerance)</li>
                        <li><strong>Manifest Creation:</strong> Generates <code>target/manifests/latest.json</code> with metadata</li>
                    </ol>
                    Output: <code>*.onnx</code> and <code>*.int8.onnx</code> files ready for the .NET gRPC service.
                </div>

                <div class="warning-box">
                    <strong>Troubleshooting export issues:</strong>
                    <ul>
                        <li>If export fails with "model not found", ensure all three models completed training successfully</li>
                        <li>If parity check fails, your model may have non-deterministic operations - check training logs</li>
                        <li>Review <code>configs/export/base.yaml</code> to specify which component versions to export</li>
        </ul>
      </div>

                <h3>Step 5: Package for Deployment</h3>
                <p>Bundle the manifest and ONNX files into a single tarball for deployment:</p>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Create deployment package</span>
                        <button class="copy-btn" data-target="package-code">Copy</button>
        </div>
                    <pre><code id="package-code">python -m sphana_trainer.cli package --config configs\export\base.yaml</code></pre>
                </div>

                <div class="success-box">
                    <strong>‚úÖ Success!</strong> Your production-ready package is at:
                    <br><code>target/manifests/latest.tar.gz</code>
                    <br><br>
                    This tarball contains:
                    <ul>
                        <li>Manifest JSON with model metadata and versions</li>
                        <li>ONNX files for all three components (standard + quantized)</li>
                        <li>Calibration data for the .NET runtime</li>
          </ul>
                    Deploy this file to your .NET gRPC service to serve the models in production.
                </div>

                <h3>Alternative: Single Command Workflow</h3>
                <p>For advanced users, run the entire pipeline (Steps 1-5) with one command:</p>

                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Complete end-to-end workflow</span>
                        <button class="copy-btn" data-target="workflow-code">Copy</button>
                    </div>
                    <pre><code id="workflow-code">python -m sphana_trainer.cli workflow run `
    --ingest-config configs\ingest\base.yaml `
    --embedding-config configs\embedding\base.yaml `
    --relation-config configs\relation\base.yaml `
    --gnn-config configs\gnn\base.yaml `
    --export-config configs\export\base.yaml `
    --package-config configs\export\base.yaml `
    --promote-component embedding `
    --promote-version 0.1.0 `
    --manifest target\manifests\latest.json `
    --build-datasets `
    --dataset-output-dir target\datasets\wiki</code></pre>
                </div>

                <div class="info-box">
                    <strong>Workflow automation benefits:</strong>
                    <ul>
                        <li><strong>State tracking:</strong> Resumes from last successful stage if interrupted</li>
                        <li><strong>Dependency management:</strong> Automatically skips stages that are up-to-date</li>
                        <li><strong>Error recovery:</strong> Use <code>--force</code> to retry failed stages</li>
                        <li><strong>Artifact promotion:</strong> Automatically promotes specified component versions</li>
                        <li><strong>Report generation:</strong> Creates <code>target/artifacts/workflow-report.json</code> with summary</li>
          </ul>
                </div>

                <h3>Next Steps</h3>
                <div class="success-box">
                    <strong>After completing the Quick Start:</strong>
                    <ul>
                        <li>üìä <strong>Review metrics:</strong> Check <code>target/logs/trainer.log</code> and MLflow UI for training curves</li>
                        <li>üîç <strong>Validate quality:</strong> Use <code>artifacts parity-samples</code> to generate test cases for the .NET service</li>
                        <li>üöÄ <strong>Deploy:</strong> Upload <code>latest.tar.gz</code> to your .NET gRPC service</li>
                        <li>üîÑ <strong>Iterate:</strong> Adjust hyperparameters with <code>train sweep</code> for better results</li>
                        <li>üìö <strong>Production setup:</strong> See <a href="#workflows">Workflows</a> section for advanced automation</li>
          </ul>
                </div>
            </section>

            <!-- Architecture -->
            <section id="architecture" class="section">
                <h2>Architecture</h2>
                
                <p>Sphana Trainer implements the training pipeline for the Neural RAG Database (NRDB), which combines vector similarity search with knowledge graph reasoning.</p>

                <div class="diagram-box">
                    <div class="pipeline-diagram">
                        <div class="pipeline-step">
                            <div class="step-number">1</div>
                            <h4>Data Ingestion</h4>
                            <p>Parse documents<br>Extract relations<br>Build datasets</p>
                        </div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">
                            <div class="step-number">2</div>
                            <h4>Model Training</h4>
                            <p>Embedding<br>Relation<br>GNN</p>
                        </div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">
                            <div class="step-number">3</div>
                            <h4>Export</h4>
                            <p>ONNX format<br>INT8 quantize<br>Validate parity</p>
                        </div>
                        <div class="pipeline-arrow">‚Üí</div>
                        <div class="pipeline-step">
                            <div class="step-number">4</div>
                            <h4>Package</h4>
                            <p>Bundle models<br>Create manifest<br>Deploy</p>
                        </div>
                    </div>
                </div>

                <h3>Design Goals</h3>
                <ul>
                    <li><strong>Low Latency:</strong> Target p95 latency below 50ms through quantization and ONNX optimization</li>
                    <li><strong>Hybrid Retrieval:</strong> Combine vector similarity with knowledge graph reasoning</li>
                    <li><strong>Production Ready:</strong> Export to ONNX with INT8 quantization for deployment</li>
                    <li><strong>Reproducible:</strong> Configuration-driven with deterministic seeding and fingerprinting</li>
            </ul>
            </section>

            <!-- Components -->
            <section id="components" class="section">
                <h2>Model Components</h2>

                <div class="intro-box">
                    <p class="lead">The Sphana Trainer produces three specialized neural models that power the <strong>Neural RAG Database (NRDB)</strong> ‚Äî a hybrid architecture that goes beyond traditional vector-only retrieval by explicitly modeling structured relationships in a Knowledge Graph (KG).</p>
                </div>

                <h3>The Neural RAG Database Architecture</h3>
                <p>Traditional RAG systems rely solely on semantic vector similarity, which fails to capture explicit structural relationships between entities. The NRDB solves this by combining:</p>
                <ul>
                    <li><strong>Dense Vector Search (HNSW/IVF):</strong> Fast semantic retrieval via approximate nearest neighbors</li>
                    <li><strong>Structured Knowledge Graph (PCSR):</strong> Explicit entity relationships stored in a disk-resident, dynamically updatable graph format</li>
                    <li><strong>Neural Graph Reasoning (GNN):</strong> Multi-hop reasoning across the KG to find logical paths connecting query entities to answers</li>
                </ul>
                <p>This hybrid approach enables the system to answer complex, multi-hop queries that require synthesizing facts across multiple context fragments ‚Äî something pure vector search cannot do reliably.</p>

                <div class="info-box">
                    <strong>Performance Target:</strong> The NRDB is designed for production RAG workloads with aggressive latency requirements: <strong>&lt;50ms p95 end-to-end retrieval</strong>. This is achieved through 8-bit quantization, ONNX Runtime acceleration, and in-memory caching.
                </div>

                <h3>How the Models Work Together</h3>
                <p>During document ingestion in the production .NET service:</p>
                <ol>
                    <li>The <strong>Embedding Encoder</strong> converts text chunks into dense 384/512-dim vectors for fast semantic search</li>
                    <li>The <strong>Relation Extraction model</strong> parses sentences to extract KG triples (subject, predicate, object)</li>
                    <li>Vectors are indexed in HNSW; triples are stored in a disk-resident PCSR graph</li>
                </ol>
                <p>During query execution:</p>
                <ol>
                    <li>Hybrid retrieval: Vector ANN search + KG entity lookup retrieve candidate subgraphs</li>
                    <li>The <strong>GNN Reasoner</strong> ranks these subgraphs by identifying and scoring logical paths</li>
                    <li>Top-ranked structured context is passed to an LLM for final answer generation</li>
                </ol>

                <hr style="margin: 3rem 0; border: none; border-top: 1px solid var(--color-border);">

                <!-- EMBEDDING ENCODER -->
                <div class="component-card">
                    <div class="component-header">
                        <h3>
                            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="display: inline-block; vertical-align: middle; margin-right: 0.5rem;">
                                <circle cx="12" cy="5" r="3"/><circle cx="12" cy="19" r="3"/><circle cx="5" cy="12" r="3"/><circle cx="19" cy="12" r="3"/>
                            </svg>
                            Embedding Encoder
                        </h3>
                        <span class="component-badge">Transformer + Contrastive Learning</span>
                    </div>
                    
                    <h4>What It Does</h4>
                    <p>The Embedding Encoder transforms text into fixed-size dense vectors that capture semantic meaning. These embeddings enable fast approximate nearest neighbor (ANN) search to find semantically similar documents, serving as the first stage of hybrid retrieval.</p>

                    <h4>How It's Used in Production</h4>
                    <ul>
                        <li><strong>Indexing:</strong> During document ingestion, all text chunks are embedded and stored in an HNSW vector index</li>
                        <li><strong>Query:</strong> User queries are embedded with the same model, then an ANN search retrieves the top-k semantically similar chunks</li>
                        <li><strong>Latency:</strong> With INT8 quantization and ONNX Runtime, inference takes ~1-2ms per chunk on GPU, ~10-20ms on CPU</li>
                    </ul>

                    <h4>Algorithms & Architecture</h4>
                    <p><strong>Base Model:</strong> The system uses pretrained sentence transformers like <code>all-MiniLM-L6-v2</code> (22.6M params, 384-dim) or <code>EmbeddingGemma</code> (308M params, 512-dim). These models are based on transformer encoders with mean pooling over token embeddings.</p>
                    
                    <p><strong>Training Method ‚Äî SimCSE (Contrastive Learning):</strong></p>
                    <ul>
                        <li><strong>Positive Pairs:</strong> Semantically similar sentences (e.g., paraphrases, Q&A pairs, or the same sentence with dropout noise)</li>
                        <li><strong>Negative Pairs:</strong> Unrelated sentences sampled from the same batch</li>
                        <li><strong>Loss Function:</strong> Contrastive loss (NT-Xent) that pulls positive pairs closer in embedding space while pushing negatives apart</li>
                        <li><strong>Normalization:</strong> All embeddings are L2-normalized, allowing fast cosine similarity via dot product</li>
                    </ul>

                    <p><strong>Why Low Dimensionality?</strong> While higher dimensions (768, 1024) offer marginal accuracy gains, the NRDB prioritizes 384-dim embeddings because:</p>
                    <ul>
                        <li>Lower memory footprint (4x reduction: 384 vs. 1536)</li>
                        <li>Faster ANN search (distance computation scales with dimensionality)</li>
                        <li>The GNN re-ranking compensates for any semantic loss from dimension reduction</li>
                    </ul>

                    <div class="component-details">
                        <div class="detail-item">
                            <strong>Base Model:</strong> all-MiniLM-L6-v2 (default) or EmbeddingGemma
                        </div>
                        <div class="detail-item">
                            <strong>Output:</strong> 384-dim (MiniLM) or 512-dim (Gemma) normalized vectors
                        </div>
                        <div class="detail-item">
                            <strong>Training Loss:</strong> Contrastive (SimCSE NT-Xent)
                        </div>
                        <div class="detail-item">
                            <strong>Evaluation Metric:</strong> Cosine similarity on validation pairs
                        </div>
                        <div class="detail-item">
                            <strong>Datasets:</strong> Custom domain pairs, MS MARCO, NLI datasets
                        </div>
                        <div class="detail-item">
                            <strong>Inference Speed:</strong> ~1-2ms/chunk (GPU, INT8), ~10-20ms (CPU)
                        </div>
                    </div>

                    <h4>Use Cases</h4>
                    <ul>
                        <li><strong>Semantic Search:</strong> Finding documents by meaning, not keywords (e.g., "neural networks" ‚âà "deep learning")</li>
                        <li><strong>Document Clustering:</strong> Grouping similar chunks for analysis or duplicate detection</li>
                        <li><strong>Recommendation:</strong> "Find more documents like this one"</li>
                        <li><strong>Hybrid Retrieval:</strong> Combining with BM25 or KG search for better recall</li>
                    </ul>
                </div>

                <!-- RELATION EXTRACTION -->
                <div class="component-card">
                    <div class="component-header">
                        <h3>
                            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="display: inline-block; vertical-align: middle; margin-right: 0.5rem;">
                                <path d="M10 13a5 5 0 007 0M15 11h.01M9 11h.01"/><circle cx="12" cy="12" r="10"/>
                            </svg>
                            Relation Extraction Model
                        </h3>
                        <span class="component-badge">Entity-Centric Dependency Trees</span>
                    </div>
                    
                    <h4>What It Does</h4>
                    <p>The Relation Extraction (RE) model converts raw text into structured Knowledge Graph triples: <code>(subject, relation, object)</code>. For example, from "Einstein developed relativity theory in 1905," it extracts: <code>(Einstein, developed, relativity_theory)</code>.</p>

                    <h4>How It's Used in Production</h4>
                    <ul>
                        <li><strong>Indexing:</strong> During ingestion, the RE model analyzes each sentence to extract entity pairs and classify their relationship</li>
                        <li><strong>KG Construction:</strong> Extracted triples are stored in a disk-resident PCSR graph with columnar properties (Parquet)</li>
                        <li><strong>Query:</strong> Enables multi-hop reasoning ‚Äî e.g., "Who invented the transistor?" can traverse: <code>(Bardeen, invented, transistor) ‚Üí (transistor, used_in, computer)</code></li>
                        <li><strong>Latency:</strong> ~5-10ms per sentence (GPU, INT8), ~30-50ms (CPU)</li>
                    </ul>

                    <h4>Algorithms & Architecture</h4>
                    <p><strong>The Entity-Centric Paradigm:</strong> Unlike traditional dependency parsing that uses the sentence's grammatical root, this model reconstructs the dependency tree with the <strong>entity as the root</strong>. This ensures the model focuses on lexical information strongly related to the entities, improving relation classification accuracy.</p>

                    <p><strong>Model Architecture:</strong></p>
                    <ul>
                        <li><strong>Base:</strong> Small BERT-based transformer or Bi-LSTM encoder</li>
                        <li><strong>Syntactic Features:</strong> Dependency path between entities encoded as edge labels (e.g., "nsubj ‚Üí verb ‚Üí dobj")</li>
                        <li><strong>Attention Mechanism:</strong> Weighted by syntactic distance from entity nodes</li>
                        <li><strong>Output:</strong> Multi-class classifier over relation types (e.g., "founded_by", "located_in", "uses")</li>
                    </ul>

                    <p><strong>Training Process:</strong></p>
                    <ol>
                        <li><strong>Dependency Parsing:</strong> Use spaCy/Stanza to generate syntactic trees</li>
                        <li><strong>Entity-Centric Reordering:</strong> Reconstruct tree with entity as root</li>
                        <li><strong>Feature Engineering:</strong> Encode tree structure as positional embeddings + edge types</li>
                        <li><strong>Classification:</strong> Train transformer to predict relation type given entity pair + tree</li>
                        <li><strong>Loss:</strong> Cross-entropy with optional class balancing for rare relations</li>
                    </ol>

                    <p><strong>Why Entity-Centric Trees?</strong> Research shows that centering the dependency tree on entities (rather than grammatical roots) achieves state-of-the-art F1 scores (74.9% on TACRED) because it reduces the syntactic distance to relation-bearing words, making patterns easier to learn.</p>

                    <div class="component-details">
                        <div class="detail-item">
                            <strong>Base Model:</strong> BERT-tiny/small or custom Bi-LSTM
                        </div>
                        <div class="detail-item">
                            <strong>Output:</strong> Relation type + confidence score
                        </div>
                        <div class="detail-item">
                            <strong>Training Loss:</strong> Cross-entropy with negative sampling
                        </div>
                        <div class="detail-item">
                            <strong>Evaluation Metric:</strong> Macro F1 score
                        </div>
                        <div class="detail-item">
                            <strong>Datasets:</strong> TACRED, Re-TACRED, SemEval 2010 Task 8
                        </div>
                        <div class="detail-item">
                            <strong>Inference Speed:</strong> ~5-10ms/sentence (GPU, INT8)
                        </div>
                    </div>

                    <h4>Use Cases</h4>
                    <ul>
                        <li><strong>Knowledge Graph Construction:</strong> Automatically building structured databases from unstructured text</li>
                        <li><strong>Multi-Hop QA:</strong> Enabling queries that require connecting multiple facts (e.g., "Where was the founder of Tesla born?")</li>
                        <li><strong>Fact Verification:</strong> Checking if extracted triples match ground truth</li>
                        <li><strong>Recommendation:</strong> Finding entities related by specific relationship types</li>
                        <li><strong>Explainability:</strong> Providing structured reasoning paths to users</li>
                    </ul>
                </div>

                <!-- GNN REASONER -->
                <div class="component-card">
                    <div class="component-header">
                        <h3>
                            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="display: inline-block; vertical-align: middle; margin-right: 0.5rem;">
                                <circle cx="18" cy="18" r="3"/><circle cx="6" cy="6" r="3"/><circle cx="18" cy="6" r="3"/><path d="M6 9v6M18 9v6M9 18h6"/>
                            </svg>
                            GNN Reasoner (Graph Neural Network)
                        </h3>
                        <span class="component-badge">Bi-directional GGNN + Listwise Ranking</span>
                    </div>
                    
                    <h4>What It Does</h4>
                    <p>The GNN Reasoner is a Graph Neural Network that ranks candidate Knowledge Subgraphs (KSGs) by relevance to a query. It identifies and scores logical reasoning paths across the KG, enabling the system to prioritize context that contains multi-hop inferential chains.</p>

                    <h4>How It's Used in Production</h4>
                    <ul>
                        <li><strong>Hybrid Retrieval:</strong> After vector ANN + KG entity lookup retrieve 100s of nodes, the GNN identifies the most relevant sub-KSGs</li>
                        <li><strong>Path Scoring:</strong> Evaluates shortest paths between query entities and potential answers, assigning relevance scores</li>
                        <li><strong>Re-ranking:</strong> Orders retrieved context so the LLM receives the best-structured reasoning paths first</li>
                        <li><strong>Latency:</strong> ~10-20ms for scoring 50-100 subgraphs (GPU, INT8)</li>
                    </ul>

                    <h4>Algorithms & Architecture</h4>
                    <p><strong>Architecture: Bi-directional Gated Graph Sequence Neural Network (GGNN)</strong></p>
                    
                    <p><strong>How It Works:</strong></p>
                    <ol>
                        <li><strong>Node Initialization:</strong> Each entity/relation node gets an initial embedding (from entity type or text embedding)</li>
                        <li><strong>Message Passing:</strong> For <code>L</code> layers, each node aggregates messages from neighbors:
                            <ul>
                                <li><strong>Incoming messages:</strong> From parent nodes (‚óÅ direction)</li>
                                <li><strong>Outgoing messages:</strong> From child nodes (‚ñ∑ direction)</li>
                                <li>Messages are weighted by learned edge-type embeddings</li>
                            </ul>
                        </li>
                        <li><strong>State Update (GRU):</strong> A Gated Recurrent Unit integrates aggregated messages with the node's current state, allowing the network to learn which information to retain or forget</li>
                        <li><strong>Readout (Max Pooling):</strong> After L layers, the final node states are max-pooled to produce a fixed-size graph embedding</li>
                        <li><strong>Scoring:</strong> A feed-forward network maps the graph embedding to a relevance score</li>
                    </ol>

                    <p><strong>Why Bi-directional?</strong> Real KGs have directed edges (e.g., "founded_by" vs. "founded"). Processing both incoming and outgoing edges separately ensures the GNN captures the full context of each node's role in reasoning paths.</p>

                    <p><strong>Training: Listwise Ranking Loss (ListNet)</strong></p>
                    <ul>
                        <li><strong>Goal:</strong> Learn to rank entire lists of candidate subgraphs, not just individual pairs</li>
                        <li><strong>Method:</strong> Given a query and N candidate KSGs with ground-truth relevance labels, ListNet minimizes cross-entropy between:
                            <ul>
                                <li>The model's predicted ranking distribution (softmax over scores)</li>
                                <li>The ground truth ranking distribution</li>
                            </ul>
                        </li>
                        <li><strong>Advantage over Pairwise Loss:</strong> Optimizes the <em>global permutation</em> of context, ensuring the synergy between retrieved facts is maximized</li>
                    </ul>

                    <p><strong>Why Listwise Loss?</strong> In RAG, the quality of LLM output depends on the <em>ordering</em> and <em>coherence</em> of the entire context window, not just individual fact relevance. Listwise ranking has been proven superior to pointwise/pairwise methods in information retrieval tasks.</p>

                    <div class="component-details">
                        <div class="detail-item">
                            <strong>Architecture:</strong> Bi-directional GGNN (3-5 message passing layers)
                        </div>
                        <div class="detail-item">
                            <strong>Output:</strong> Relevance scores for candidate subgraphs
                        </div>
                        <div class="detail-item">
                            <strong>Training Loss:</strong> ListNet (listwise ranking loss)
                        </div>
                        <div class="detail-item">
                            <strong>Evaluation Metric:</strong> NDCG@k, MRR (Mean Reciprocal Rank)
                        </div>
                        <div class="detail-item">
                            <strong>Datasets:</strong> Synthetic question graphs from KG, KGQA benchmarks
                        </div>
                        <div class="detail-item">
                            <strong>Inference Speed:</strong> ~10-20ms for 50-100 subgraphs (GPU, INT8)
                        </div>
                    </div>

                    <h4>Use Cases</h4>
                    <ul>
                        <li><strong>Complex QA:</strong> Multi-hop questions requiring chaining facts across entities (e.g., "What university did the inventor of PageRank attend?")</li>
                        <li><strong>Explainable AI:</strong> Providing users with structured reasoning paths showing how the answer was derived</li>
                        <li><strong>Context Optimization:</strong> Ensuring LLMs receive the most relevant, well-structured context for generation</li>
                        <li><strong>Knowledge Validation:</strong> Scoring the plausibility of reasoning chains in the KG</li>
                        <li><strong>Subgraph Mining:</strong> Finding densely connected, semantically coherent regions of the KG</li>
                    </ul>
                </div>

                <hr style="margin: 3rem 0; border: none; border-top: 1px solid var(--color-border);">

                <h3>Production Optimization</h3>
                <p>All three models undergo aggressive optimization for production deployment:</p>
                <ul>
                    <li><strong>ONNX Export:</strong> Models are converted to the ONNX format for platform-agnostic, optimized inference</li>
                    <li><strong>INT8 Quantization:</strong> Weights and activations are quantized to 8-bit integers, reducing model size by ~50% and inference time by 2-4x with minimal accuracy loss (&lt;1%)</li>
                    <li><strong>ONNX Runtime:</strong> The .NET service uses ONNX Runtime with CUDA acceleration for GPU inference or highly optimized CPU execution</li>
                    <li><strong>Batch Processing:</strong> Requests are micro-batched (5-10ms windows) to maximize GPU utilization</li>
                    <li><strong>Caching:</strong> Frequently requested embeddings and subgraph scores are cached in Redis</li>
                </ul>

                <div class="success-box">
                    <strong>Result:</strong> The complete NRDB retrieval pipeline (vector search + KG traversal + GNN ranking) achieves <strong>&lt;50ms p95 latency</strong> on commodity GPU hardware, making it suitable for production RAG applications requiring both speed and structured reasoning.
                </div>
            </section>

            <!-- Workflow -->
            <section id="workflow" class="section">
                <h2>Training Workflow</h2>

                <p>The complete training pipeline consists of four stages:</p>

                <div class="workflow-stages">
                    <div class="stage">
                        <div class="stage-icon">
                            <svg width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="color: var(--color-primary);">
                                <path d="M21 15v4a2 2 0 01-2 2H5a2 2 0 01-2-2v-4M7 10l5 5 5-5M12 15V3"/>
                            </svg>
                        </div>
                        <h3>Stage 1: Ingestion</h3>
                        <p>Process raw documents into structured data:</p>
                        <ul>
                            <li>Parse documents (spaCy, Stanza, or simple)</li>
                            <li>Extract entities and relations</li>
                            <li>Create knowledge graph triples</li>
                            <li>Cache parsed data for reuse</li>
          </ul>
                        <div class="code-snippet">
                            <code>python -m sphana_trainer.cli ingest --config configs/ingest/wiki.yaml</code>
                        </div>
                    </div>

                    <div class="stage">
                        <div class="stage-icon">
                            <svg width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="color: var(--color-primary);">
                                <path d="M3 3h7v7H3zM14 3h7v7h-7zM14 14h7v7h-7zM3 14h7v7H3z"/>
                            </svg>
                        </div>
                        <h3>Stage 2: Dataset Building</h3>
                        <p>Transform ingestion outputs into training datasets:</p>
                        <ul>
                            <li>Create embedding pairs (query/context)</li>
                            <li>Build relation classification samples</li>
                            <li>Generate GNN training subgraphs</li>
                            <li>Split into train/validation sets</li>
          </ul>
                        <div class="code-snippet">
                            <code>python -m sphana_trainer.cli dataset-build-from-ingest &lt;ingest_dir&gt;</code>
                        </div>
                    </div>

                    <div class="stage">
                        <div class="stage-icon">
                            <svg width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="color: var(--color-primary);">
                                <path d="M22 10v6M2 10l10-5 10 5-10 5z"/><path d="M6 12v5c3 3 9 3 12 0v-5"/>
                            </svg>
                        </div>
                        <h3>Stage 3: Training</h3>
                        <p>Train each neural component:</p>
                        <ul>
                            <li>Fine-tune on prepared datasets</li>
                            <li>Mixed precision training (fp16/bf16)</li>
                            <li>Early stopping and checkpointing</li>
                            <li>Optional MLflow experiment tracking</li>
          </ul>
                        <div class="code-snippet">
                            <code>python -m sphana_trainer.cli train embedding --config configs/embedding/base.yaml</code>
                        </div>
                    </div>

                    <div class="stage">
                        <div class="stage-icon">
                            <svg width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="color: var(--color-primary);">
                                <path d="M16 16l-4 4m0 0l-4-4m4 4V4"/><path d="M20 20H4"/>
                            </svg>
                        </div>
                        <h3>Stage 4: Export & Package</h3>
                        <p>Prepare models for deployment:</p>
                        <ul>
                            <li>Export to ONNX format</li>
                            <li>Apply INT8 quantization</li>
                            <li>Generate manifest with metadata</li>
                            <li>Package into deployment tarball</li>
          </ul>
                        <div class="code-snippet">
                            <code>python -m sphana_trainer.cli export --config configs/export/base.yaml</code>
                        </div>
                    </div>
                </div>

                <div class="info-box" style="padding-left: 3.5rem;">
                    <strong>Automate Everything:</strong> Use <code>workflow run</code> or <code>workflow wiki</code> to execute all stages automatically with state tracking.
                </div>
            </section>

            <!-- Data Preparation -->
            <section id="data-preparation" class="section">
                <h2>Data Preparation</h2>

                <h3>Document Ingestion</h3>
                <p>Start with raw text documents in any of these formats:</p>
                <ul>
                    <li><code>.txt</code> - Plain text files</li>
                    <li><code>.md</code> - Markdown documents</li>
                    <li><code>.json</code>/<code>.jsonl</code> - Structured data with <code>title</code> and <code>content</code></li>
          </ul>

                <h4>Configure Ingestion</h4>
                <p>Edit <code>configs/ingest/base.yaml</code> or create your own:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">YAML</span>
                    </div>
                    <pre><code>ingest:
  input_dir: data/my-documents
  output_dir: target/ingest/my-corpus
  chunk_size: 120
  chunk_overlap: 20
  parser: spacy              # simple, spacy, or stanza
  parser_model: en_core_web_sm
  relation_threshold: 0.5</code></pre>
                </div>

                <h4>Run Ingestion</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli ingest --config configs/ingest/base.yaml</code></pre>
                </div>

                <p><strong>Output:</strong></p>
                <ul>
                    <li><code>chunks.jsonl</code> - Text chunks with embeddings</li>
                    <li><code>relations.jsonl</code> - Extracted knowledge graph triples</li>
                    <li><code>cache/</code> - Cached parses for reproducibility</li>
          </ul>

                <h3>Dataset Building</h3>
                <p>Convert ingestion outputs into training-ready datasets:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli dataset-build-from-ingest target/ingest/my-corpus \
    --output-dir target/datasets/my-corpus \
    --min-confidence 0.3 \
    --val-ratio 0.2 \
    --seed 42</code></pre>
                </div>

                <p><strong>Output:</strong></p>
                <ul>
                    <li><code>embedding/train.jsonl</code> - Query/context pairs</li>
                    <li><code>relation/train.jsonl</code> - Entity-relation-entity triples</li>
                    <li><code>gnn/train.jsonl</code> - Knowledge subgraphs with rankings</li>
                    <li>Corresponding validation sets</li>
          </ul>

                <h3>Download Wikipedia Data</h3>
                <p>Download Wikipedia articles (summaries or full content):</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Summaries (default, fast)</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli dataset-download-wiki `
    --output target\data\docs.jsonl `
    --title "Machine learning" `
    --title "Deep learning" `
    --title "Natural language processing" `
    --title "Neural network" `
    --full-content</code></pre>
                </div>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Full content (comprehensive)</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli dataset-download-wiki `
    --output target\data\docs.jsonl `
    --titles-file samples\ai-ml-wiki-titles.medium.txt `
    --full-content `
    --limit 10000</code></pre>
                </div>
            </section>

            <!-- Training -->
            <section id="training" class="section">
                <h2>Training Models</h2>

                <h3>Train Individual Components</h3>
                
                <h4>Embedding Model</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli train embedding --config configs/embedding/base.yaml</code></pre>
                </div>
                <p>Fine-tunes a sentence transformer for semantic similarity using contrastive learning.</p>

                <h4>Relation Extraction Model</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli train relation --config configs/relation/base.yaml</code></pre>
                </div>
                <p>Trains a classifier to extract knowledge graph relations from text.</p>

                <h4>GNN Reasoner</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli train gnn --config configs/gnn/base.yaml</code></pre>
                </div>
                <p>Trains a graph neural network to rank knowledge subgraphs.</p>

                <h3>Training Options</h3>
                <table class="options-table">
            <thead>
              <tr>
                            <th>Option</th>
                <th>Description</th>
                            <th>Example</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                            <td><code>--precision</code></td>
                            <td>Training precision</td>
                            <td><code>fp32</code>, <code>fp16</code>, <code>bf16</code></td>
              </tr>
              <tr>
                            <td><code>--grad-accum</code></td>
                            <td>Gradient accumulation steps</td>
                            <td><code>--grad-accum 4</code></td>
              </tr>
              <tr>
                            <td><code>--profile-steps</code></td>
                            <td>Profile N training steps</td>
                            <td><code>--profile-steps 10</code></td>
              </tr>
              <tr>
                <td><code>--mlflow-tracking-uri</code></td>
                            <td>MLflow server URL</td>
                            <td><code>file:///path/to/mlruns</code></td>
              </tr>
            </tbody>
          </table>

                <h3>Hyperparameter Sweeps</h3>
                <p>Run grid search over hyperparameters:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli train sweep embedding \
    --config configs/embedding/base.yaml \
    --lr 2e-5 --lr 5e-5 \
    --batch-size 16 --batch-size 32 \
    --temperature 0.05 --temperature 0.07</code></pre>
                </div>
                <p>Results are automatically logged to MLflow for comparison.</p>

                <h3>Monitor Training</h3>
                <ul>
                    <li><strong>Logs:</strong> Check <code>target/logs/trainer.log</code></li>
                    <li><strong>Checkpoints:</strong> Saved to <code>target/artifacts/&lt;component&gt;/</code></li>
                    <li><strong>MLflow:</strong> View at <code>target/mlruns</code> (or your tracking URI)</li>
                    <li><strong>Metrics:</strong> Validation metrics saved to <code>metrics.jsonl</code></li>
            </ul>
            </section>

            <!-- Export & Package -->
            <section id="export-package" class="section">
                <h2>Export & Package</h2>

                <h3>Export to ONNX</h3>
                <p>Convert trained PyTorch models to ONNX format with quantization:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli export --config configs/export/base.yaml</code></pre>
                </div>

                <p>This command:</p>
                <ul>
                    <li>Exports all trained models to ONNX format (opset 17)</li>
                    <li>Applies INT8 dynamic quantization to reduce size</li>
                    <li>Validates ONNX output against PyTorch reference</li>
                    <li>Generates a deployment manifest at <code>target/manifests/latest.json</code></li>
          </ul>

                <h3>Create Deployment Package</h3>
                <p>Bundle ONNX models and manifest into a single tarball:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli package --config configs/export/base.yaml</code></pre>
                </div>

                <p><strong>Output:</strong> <code>target/manifests/latest.tar.gz</code></p>
                <p>This tarball contains everything the .NET gRPC service needs to run inference.</p>

                <h3>Artifact Management</h3>
                
                <h4>List Artifacts</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli artifacts list</code></pre>
                </div>

                <h4>Show Artifact Details</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli artifacts show embedding 0.1.0</code></pre>
                </div>

                <h4>Promote Artifact</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli artifacts promote embedding 0.1.0 \
    --manifest target/manifests/promoted.json</code></pre>
                </div>

                <h4>Bundle Artifacts</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli artifacts bundle embedding 0.1.0 target/bundles/embedding</code></pre>
                </div>
            </section>

            <!-- Workflows -->
            <section id="workflows" class="section">
                <h2>Automated Workflows</h2>

                <p>Workflows automate the complete pipeline from ingestion to packaging with state tracking.</p>

                <h3>Custom Workflow</h3>
                <p>Run a complete training pipeline with your configurations:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                        <button class="copy-btn" data-target="workflow-custom">Copy</button>
                    </div>
                    <pre><code id="workflow-custom">python -m sphana_trainer.cli workflow run \
    --ingest-config configs/ingest/wiki.yaml \
    --embedding-config configs/embedding/wiki.yaml \
    --relation-config configs/relation/wiki.yaml \
    --gnn-config configs/gnn/wiki.yaml \
    --export-config configs/export/base.yaml \
    --package-config configs/export/base.yaml \
    --promote-component embedding \
    --promote-version 0.1.0 \
    --manifest target/manifests/latest.json \
    --build-datasets \
    --dataset-output-dir target/datasets/wiki \
    --mlflow-tracking-uri target/mlruns</code></pre>
                </div>

                <h3>Wikipedia Workflow</h3>
                <p>Pre-configured workflow for the Wikipedia corpus:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli workflow wiki</code></pre>
                </div>
                <p>This command automatically:</p>
                <ol>
                    <li>Downloads Wikipedia articles</li>
                    <li>Runs ingestion with spaCy/Stanza parsers</li>
                    <li>Builds training datasets</li>
                    <li>Trains all three models</li>
                    <li>Exports to ONNX with quantization</li>
                    <li>Packages for deployment</li>
                    <li>Generates parity test fixtures</li>
                </ol>

                <h3>Workflow State</h3>
                <p>Workflows track which stages have completed successfully:</p>
                
                <h4>Check Status</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>python -m sphana_trainer.cli workflow status</code></pre>
                </div>

                <h4>Force Re-run</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code># Re-run everything
python -m sphana_trainer.cli workflow run --force ...

# Re-run specific stage
python -m sphana_trainer.cli workflow run --force-stage training ...</code></pre>
                </div>

                <div class="info-box" style="padding-left: 3.5rem;">
                    <strong>Workflow Reports:</strong> After completion, check <code>target/artifacts/workflow-report.json</code> for a complete summary of the pipeline execution.
                </div>
            </section>

            <!-- CLI Reference -->
            <section id="cli-reference" class="section">
                <h2>CLI Command Reference</h2>

                <div class="command-group">
                    <h3>Training Commands</h3>
                    
                    <div class="command-ref">
                        <h4><code>train embedding</code></h4>
                        <p>Train the embedding encoder model.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>train embedding --config &lt;path&gt; [options]</code>
                        </div>
                        <div class="command-options">
                            <strong>Options:</strong>
                            <ul>
                                <li><code>--config PATH</code> - Configuration file (required)</li>
                                <li><code>--precision {fp32,fp16,bf16}</code> - Training precision</li>
                                <li><code>--grad-accum N</code> - Gradient accumulation steps</li>
                                <li><code>--profile-steps N</code> - Enable profiling for N steps</li>
          </ul>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>train relation</code></h4>
                        <p>Train the relation extraction model.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>train relation --config &lt;path&gt; [options]</code>
                        </div>
                        <div class="command-options">
                            <strong>Options:</strong>
                            <ul>
                                <li><code>--config PATH</code> - Configuration file (required)</li>
                                <li><code>--precision {fp32,fp16,bf16}</code> - Training precision</li>
                                <li><code>--grad-accum N</code> - Gradient accumulation steps</li>
                                <li><code>--profile-steps N</code> - Enable profiling for N steps</li>
          </ul>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>train gnn</code></h4>
                        <p>Train the GNN reasoner model.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>train gnn --config &lt;path&gt; [options]</code>
                        </div>
                        <div class="command-options">
                            <strong>Options:</strong>
                            <ul>
                                <li><code>--config PATH</code> - Configuration file (required)</li>
                                <li><code>--precision {fp32,fp16,bf16}</code> - Training precision</li>
                                <li><code>--grad-accum N</code> - Gradient accumulation steps</li>
                                <li><code>--profile-steps N</code> - Enable profiling for N steps</li>
          </ul>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>train sweep &lt;component&gt;</code></h4>
                        <p>Run a small hyperparameter sweep for a component. Results are automatically logged to MLflow.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>train sweep {embedding|relation|gnn} --config &lt;path&gt; [--param val1 --param val2 ...]</code>
                        </div>
                        <div class="command-options">
                            <strong>Options:</strong>
                            <ul>
                                <li><code>--config PATH</code> - Base configuration file (required)</li>
                                <li><code>--lr FLOAT</code> - Learning rates to explore (can be repeated)</li>
                                <li><code>--batch-size INT</code> - Batch sizes to explore (can be repeated)</li>
                                <li><code>--temperature FLOAT</code> - Embedding temperature values (embedding only, can be repeated)</li>
                                <li><code>--hidden-dim INT</code> - GNN hidden dimensions (GNN only, can be repeated)</li>
                                <li><code>--grid-file PATH</code> - YAML file describing sweep overrides</li>
                                <li><code>--mlflow-tracking-uri URI</code> - Override MLflow tracking URI for sweep runs</li>
          </ul>
                        </div>
                        <div class="command-example">
                            <strong>Example:</strong>
                            <pre><code>train sweep embedding --config base.yaml --lr 1e-5 --lr 5e-5 --batch-size 16 --batch-size 32</code></pre>
                        </div>
                    </div>
                </div>

                <div class="command-group">
                    <h3>Data Commands</h3>
                    
                    <div class="command-ref">
                        <h4><code>ingest</code></h4>
                        <p>Process raw documents and extract knowledge graph triples.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>ingest --config &lt;path&gt; [--force]</code>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>dataset-build-from-ingest</code></h4>
                        <p>Convert ingestion outputs (chunks.jsonl/relations.jsonl) into training-ready splits for embedding, relation, and GNN models.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>dataset-build-from-ingest &lt;ingest_dir&gt; [options]</code>
                        </div>
                        <div class="command-options">
                            <strong>Options:</strong>
                            <ul>
                                <li><code>--output-dir PATH</code> - Output directory (default: target/datasets)</li>
                                <li><code>--min-confidence FLOAT</code> - Minimum relation confidence to keep (default: 0.2)</li>
                                <li><code>--val-ratio FLOAT</code> - Validation split ratio (default: 0.2)</li>
                                <li><code>--seed INT</code> - Random seed for deterministic shuffling (default: 42)</li>
                                <li><code>--extra-embedding PATH</code> - Additional embedding JSONL files (can be repeated)</li>
                                <li><code>--extra-relation PATH</code> - Additional relation JSONL files (can be repeated)</li>
                                <li><code>--extra-gnn PATH</code> - Additional GNN JSONL files (can be repeated)</li>
                                <li><code>--parses-dir PATH</code> - Optional directory containing cached parse JSON files</li>
          </ul>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>dataset-download-wiki</code></h4>
                        <p>Download Wikipedia articles (summaries or full content) into JSONL format. Requires <code>--title</code> or <code>--titles-file</code>.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>dataset-download-wiki --title TEXT | --titles-file PATH [options]</code>
                        </div>
                        <div class="command-options">
                            <strong>Required (at least one):</strong>
                            <ul>
                                <li><code>--title TEXT</code> - Specific Wikipedia titles to download (can be repeated for multiple titles)</li>
                                <li><code>--titles-file PATH</code> - File with titles (one per line)</li>
                            </ul>
                            <strong>Options:</strong>
                            <ul>
                                <li><code>--output PATH</code> - Destination JSONL file (default: target\data\docs.jsonl)</li>
                                <li><code>--limit N</code> - Maximum number of pages to fetch from the title list</li>
                                <li><code>--shuffle/--no-shuffle</code> - Shuffle the title list before downloading (default: shuffle)</li>
                                <li><code>--full-content</code> - Download full article content instead of summaries (slower but comprehensive)</li>
          </ul>
                        </div>
                        <div class="info-box">
                            <strong>üìù Two Modes:</strong>
                            <ul>
                                <li><strong>Default (summaries):</strong> Fetches article introductions (1-3 paragraphs) - fast, good for quick testing</li>
                                <li><strong>Full content (<code>--full-content</code>):</strong> Fetches complete article text - comprehensive, better for training</li>
                            </ul>
                            <br>
                            <strong>Examples:</strong>
                            <pre style="margin-top: 0.5rem;"><code># Summaries (fast)
python -m sphana_trainer.cli dataset-download-wiki `
    --title "Machine learning" `
    --output wiki-summaries.jsonl

# Full content (comprehensive)
python -m sphana_trainer.cli dataset-download-wiki `
    --titles-file samples\ai-ml-wiki-titles.txt `
    --full-content `
    --limit 500 `
    --output wiki-full.jsonl</code></pre>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>dataset-validate</code></h4>
                        <p>Validate dataset against schema.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>dataset-validate &lt;file&gt; --type {embedding,relation,gnn}</code>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>dataset-stats</code></h4>
                        <p>Compute simple dataset statistics.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>dataset-stats &lt;file&gt; [--limit N]</code>
                        </div>
                        <div class="command-example">
                            <strong>Example:</strong>
                            <pre><code>python -m sphana_trainer.cli dataset-stats src/tests/data/embedding/train.jsonl</code></pre>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>ingest-validate</code></h4>
                        <p>Run ingestion and validate outputs against schemas.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>ingest-validate --config &lt;path&gt; [--stats] [--chunks-schema &lt;path&gt;] [--relations-schema &lt;path&gt;]</code>
                        </div>
                        <div class="command-example">
                            <strong>Example:</strong>
                            <pre><code>python -m sphana_trainer.cli ingest-validate --config configs/ingest/base.yaml --stats \
    --chunks-schema src/sphana_trainer/schemas/ingestion/chunks.schema.json \
    --relations-schema src/sphana_trainer/schemas/ingestion/relations.schema.json</code></pre>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>ingest-cache-models</code></h4>
                        <p>Pre-download spaCy/Stanza/Relation models so ingestion never pauses mid-run.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>ingest-cache-models [--relation-model &lt;id&gt;] [--spacy-model &lt;name&gt;] [--stanza-lang &lt;code&gt;]</code>
                        </div>
                        <div class="command-options">
                            <strong>Options:</strong>
                            <ul>
                                <li><code>--relation-model</code> - Hugging Face model ID (e.g., hf-internal-testing/tiny-random-bert)</li>
                                <li><code>--spacy-model</code> - spaCy pipeline name (e.g., en_core_web_sm)</li>
                                <li><code>--stanza-lang</code> - Stanza language code (e.g., en)</li>
          </ul>
                        </div>
                        <div class="command-example">
                            <strong>Example:</strong>
                            <pre><code>python -m sphana_trainer.cli ingest-cache-models \
    --relation-model hf-internal-testing/tiny-random-bert \
    --spacy-model en_core_web_sm \
    --stanza-lang en</code></pre>
                        </div>
                    </div>
                </div>

                <div class="command-group">
                    <h3>Export Commands</h3>
                    
                    <div class="command-ref">
                        <h4><code>export</code></h4>
                        <p>Export trained models to ONNX format.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>export --config &lt;path&gt;</code>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>package</code></h4>
                        <p>Package ONNX models and manifest into tarball.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>package --config &lt;path&gt;</code>
                        </div>
                    </div>
                </div>

                <div class="command-group">
                    <h3>Artifact Commands</h3>
                    
                    <div class="command-ref">
                        <h4><code>artifacts list</code></h4>
                        <p>List all trained artifacts.</p>
                    </div>

                    <div class="command-ref">
                        <h4><code>artifacts show</code></h4>
                        <p>Show details for a specific artifact.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>artifacts show &lt;component&gt; &lt;version&gt;</code>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>artifacts promote</code></h4>
                        <p>Promote an artifact version to production.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>artifacts promote &lt;component&gt; &lt;version&gt; [options]</code>
                        </div>
                        <div class="command-options">
                            <strong>Options:</strong>
                            <ul>
                                <li><code>--artifact-root PATH</code> - Artifact root directory (default: target/artifacts)</li>
                                <li><code>--manifest PATH</code> - Optional manifest file to update after promotion</li>
                                <li><code>--publish-url URL</code> - Optional URL of the .NET service to publish manifests to</li>
          </ul>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>artifacts bundle</code></h4>
                        <p>Bundle artifact files for distribution.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>artifacts bundle &lt;component&gt; &lt;version&gt; &lt;output_dir&gt;</code>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>artifacts diff</code></h4>
                        <p>Compare metadata between two artifact versions.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>artifacts diff &lt;component&gt; &lt;version_a&gt; &lt;version_b&gt;</code>
                        </div>
                        <div class="command-example">
                            <strong>Example:</strong>
                            <pre><code>python -m sphana_trainer.cli artifacts diff embedding 0.1.0 0.2.0</code></pre>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>artifacts parity-samples</code></h4>
                        <p>Generate ONNX parity samples consumable by the .NET service for inference validation.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>artifacts parity-samples &lt;component&gt; &lt;sample_file&gt; &lt;output&gt;</code>
                        </div>
                        <div class="command-example">
                            <strong>Example:</strong>
                            <pre><code>python -m sphana_trainer.cli artifacts parity-samples embedding `
    samples\embedding_samples.jsonl `
    target\artifacts\parity\embedding-parity.json</code></pre>
                        </div>
                    </div>
                </div>

                <div class="command-group">
                    <h3>Workflow Commands</h3>
                    
                    <div class="command-ref">
                        <h4><code>workflow run</code></h4>
                        <p>Execute complete training pipeline (training ‚Üí export ‚Üí ingestion ‚Üí validation ‚Üí artifact ops).</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>workflow run [--ingest-config PATH] [--embedding-config PATH] [--relation-config PATH] [--gnn-config PATH] [--export-config PATH] [--package-config PATH] [--promote-component NAME] [--promote-version VER] [--manifest PATH] [--build-datasets] [--dataset-output-dir PATH]</code>
                        </div>
                        <div class="command-options">
                            <strong>Key Options:</strong>
                            <ul>
                                <li><code>--ingest-config</code> - Ingestion configuration file</li>
                                <li><code>--embedding-config</code>, <code>--relation-config</code>, <code>--gnn-config</code> - Training configs for each component</li>
                                <li><code>--export-config</code>, <code>--package-config</code> - Export and packaging configurations</li>
                                <li><code>--promote-component</code>, <code>--promote-version</code> - Component and version to promote</li>
                                <li><code>--manifest</code> - Output manifest path</li>
                                <li><code>--build-datasets</code> - Build datasets from ingestion</li>
                                <li><code>--dataset-output-dir</code> - Where to write derived datasets</li>
          </ul>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>workflow wiki</code></h4>
                        <p>Run pre-configured Wikipedia workflow.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>workflow wiki [--artifact-root PATH]</code>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>workflow status</code></h4>
                        <p>Check workflow execution status.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>workflow status [--artifact-root &lt;path&gt;]</code>
                        </div>
                        <div class="command-example">
                            <strong>Example:</strong>
                            <pre><code>python -m sphana_trainer.cli workflow status --artifact-root target/artifacts</code></pre>
                        </div>
                    </div>
                </div>

                <div class="command-group">
                    <h3>Metrics & Profiling Commands</h3>
                    
                    <div class="command-ref">
                        <h4><code>metrics summarize</code></h4>
                        <p>Aggregate telemetry snapshots captured during training/ingestion (GPU/CPU/RAM utilization, throughput).</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>metrics summarize [--metrics-dir &lt;path&gt;] [--component &lt;name&gt;] [--latest]</code>
                        </div>
                        <div class="command-options">
                            <strong>Options:</strong>
                            <ul>
                                <li><code>--metrics-dir</code> - Directory containing metrics JSON files (default: target/metrics)</li>
                                <li><code>--component</code> - Filter by component name (embedding, relation, gnn)</li>
                                <li><code>--latest</code> - Show only the most recent run per component</li>
          </ul>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>profile traces</code></h4>
                        <p>Review and export PyTorch profiler traces collected during training.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>profile traces [--profile-dir &lt;path&gt;] [--component &lt;name&gt;] [--open] [--export &lt;path&gt;]</code>
                        </div>
                        <div class="command-options">
                            <strong>Options:</strong>
                            <ul>
                                <li><code>--profile-dir</code> - Directory containing trace files</li>
                                <li><code>--component</code> - Filter to specific component traces</li>
                                <li><code>--open</code> - Launch Chrome trace viewer</li>
                                <li><code>--export</code> - Export trace to specified path</li>
          </ul>
                        </div>
                    </div>

                    <div class="command-ref">
                        <h4><code>version</code></h4>
                        <p>Print the CLI version number.</p>
                        <div class="command-syntax">
                            <strong>Syntax:</strong> <code>version</code>
                        </div>
                        <div class="command-example">
                            <strong>Example:</strong>
                            <pre><code>python -m sphana_trainer.cli version</code></pre>
                        </div>
                    </div>
                </div>
      </section>

            <!-- Configuration -->
            <section id="configuration" class="section">
                <h2>Configuration</h2>

                <p>All models are configured using YAML files in the <code>configs/</code> directory.</p>

                <h3>Configuration Structure</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">YAML</span>
                    </div>
                    <pre><code>workspace_dir: target/workspace
artifact_root: target/artifacts
embedding:
  # Embedding model configuration
relation:
  # Relation extraction configuration
gnn:
  # GNN reasoner configuration
export:
  # Export settings</code></pre>
                </div>

                <h3>Embedding Configuration</h3>
                <table class="config-table">
          <thead>
            <tr>
                            <th>Parameter</th>
              <th>Type</th>
              <th>Default</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>model_name</code></td>
                            <td>string</td>
                            <td>all-MiniLM-L6-v2</td>
                            <td>Base model identifier</td>
            </tr>
            <tr>
                            <td><code>batch_size</code></td>
                            <td>int</td>
                            <td>32</td>
                            <td>Training batch size</td>
            </tr>
            <tr>
                            <td><code>learning_rate</code></td>
                            <td>float</td>
                            <td>5e-5</td>
                            <td>Learning rate</td>
            </tr>
            <tr>
                            <td><code>epochs</code></td>
                            <td>int</td>
                            <td>3</td>
                            <td>Number of training epochs</td>
            </tr>
            <tr>
              <td><code>max_seq_length</code></td>
                            <td>int</td>
              <td>512</td>
                            <td>Maximum sequence length</td>
            </tr>
            <tr>
              <td><code>temperature</code></td>
                            <td>float</td>
              <td>0.05</td>
                            <td>Contrastive loss temperature</td>
            </tr>
            <tr>
                            <td><code>quantize</code></td>
                            <td>bool</td>
                            <td>true</td>
                            <td>Enable INT8 quantization</td>
            </tr>
          </tbody>
        </table>

                <h3>Relation Extraction Configuration</h3>
                <table class="config-table">
          <thead>
            <tr>
                            <th>Parameter</th>
              <th>Type</th>
              <th>Default</th>
                            <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
                            <td><code>model_name</code></td>
                            <td>string</td>
                            <td>(required)</td>
                            <td>BERT-based model</td>
            </tr>
            <tr>
              <td><code>max_seq_length</code></td>
              <td>int</td>
              <td>256</td>
                            <td>Maximum sequence length</td>
            </tr>
            <tr>
                            <td><code>negative_sampling_ratio</code></td>
                            <td>float</td>
                            <td>0.5</td>
                            <td>Ratio of negative samples</td>
            </tr>
            <tr>
              <td><code>early_stopping_patience</code></td>
              <td>int</td>
              <td>2</td>
                            <td>Early stopping patience</td>
            </tr>
            <tr>
              <td><code>metric_threshold</code></td>
              <td>float</td>
                            <td>null</td>
                            <td>Minimum macro F1 score</td>
            </tr>
          </tbody>
        </table>

                <h3>GNN Configuration</h3>
                <table class="config-table">
          <thead>
            <tr>
                            <th>Parameter</th>
              <th>Type</th>
              <th>Default</th>
                            <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>hidden_dim</code></td>
                            <td>int</td>
              <td>256</td>
                            <td>Hidden layer dimension</td>
            </tr>
            <tr>
              <td><code>num_layers</code></td>
                            <td>int</td>
              <td>4</td>
                            <td>Number of GNN layers</td>
            </tr>
            <tr>
                            <td><code>dropout</code></td>
                            <td>float</td>
                            <td>0.1</td>
                            <td>Dropout probability</td>
                        </tr>
                        <tr>
                            <td><code>listwise_loss</code></td>
                            <td>string</td>
                            <td>listnet</td>
                            <td>Ranking loss function</td>
            </tr>
            <tr>
              <td><code>temperature</code></td>
              <td>float</td>
              <td>1.0</td>
                            <td>Ranking temperature</td>
            </tr>
            <tr>
                            <td><code>max_nodes</code></td>
                            <td>int</td>
                            <td>128</td>
                            <td>Maximum nodes per graph</td>
                        </tr>
                        <tr>
                            <td><code>max_edges</code></td>
                            <td>int</td>
                            <td>512</td>
                            <td>Maximum edges per graph</td>
            </tr>
          </tbody>
        </table>

                <h3>Common Parameters</h3>
                <table class="config-table">
          <thead>
            <tr>
                            <th>Parameter</th>
                            <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
                            <td><code>seed</code></td>
                            <td>Random seed for reproducibility</td>
            </tr>
            <tr>
                            <td><code>warmup_ratio</code></td>
                            <td>Learning rate warmup ratio (0.0-1.0)</td>
            </tr>
            <tr>
                            <td><code>gradient_accumulation</code></td>
                            <td>Steps to accumulate gradients</td>
            </tr>
            <tr>
                            <td><code>ddp</code></td>
                            <td>Enable distributed training</td>
            </tr>
            <tr>
                            <td><code>precision</code></td>
                            <td>Training precision (fp32, fp16, bf16)</td>
            </tr>
            <tr>
                            <td><code>max_checkpoints</code></td>
                            <td>Number of checkpoints to keep</td>
                        </tr>
                        <tr>
                            <td><code>log_to_mlflow</code></td>
                            <td>Enable MLflow experiment tracking</td>
            </tr>
          </tbody>
        </table>
            </section>

            <!-- API -->
            <section id="api" class="section">
                <h2>Python API</h2>

                <p>While Sphana Trainer is primarily a CLI tool, you can also use its components programmatically.</p>

                <h3>Training</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Python</span>
        </div>
                    <pre><code>from sphana_trainer.config import load_config
from sphana_trainer.tasks import EmbeddingTask

# Load configuration
config = load_config("configs/embedding/base.yaml")

# Create and run task
task = EmbeddingTask(config.embedding)
task.execute()</code></pre>
                </div>

                <h3>Data Pipeline</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Python</span>
                    </div>
                    <pre><code>from sphana_trainer.data.pipeline import IngestionPipeline, load_ingest_config

# Load ingestion config
config = load_ingest_config("configs/ingest/base.yaml")

# Run ingestion
pipeline = IngestionPipeline(config)
pipeline.run()</code></pre>
                </div>

                <h3>Export</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Python</span>
                    </div>
                    <pre><code>from sphana_trainer.tasks import ExportTask
from sphana_trainer.config import load_config

config = load_config("configs/export/base.yaml")
task = ExportTask(config.export)
task.execute()</code></pre>
                </div>
            </section>

            <!-- Distributed Training -->
            <section id="distributed" class="section">
                <h2>Distributed Training</h2>

                <p>Sphana Trainer supports multi-GPU training using PyTorch's Distributed Data Parallel (DDP).</p>

                <h3>Setup</h3>
                <ol>
                    <li>Enable DDP in your configuration:
                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-label">YAML</span>
                            </div>
                            <pre><code>embedding:
  ddp: true
  precision: bf16  # Recommended for multi-GPU</code></pre>
                        </div>
                    </li>
                    <li>Launch with <code>torchrun</code>:
                        <div class="code-block">
                            <div class="code-header">
                                <span class="code-label">Command</span>
                            </div>
                            <pre><code>torchrun --nproc_per_node=4 -m sphana_trainer.cli train embedding --config configs/embedding/base.yaml</code></pre>
                        </div>
                    </li>
                </ol>

                <h3>Considerations</h3>
                <ul>
                    <li><strong>Batch Size:</strong> Effective batch size = <code>batch_size √ó num_gpus</code></li>
                    <li><strong>Learning Rate:</strong> May need adjustment for larger effective batch sizes</li>
                    <li><strong>Checkpointing:</strong> Only rank 0 saves checkpoints</li>
                    <li><strong>Logging:</strong> MLflow logging only from rank 0</li>
        </ul>

                <div class="warning-box" style="padding-left: 3.5rem;">
                    <strong>Important:</strong> Ensure all GPUs have the same architecture and memory capacity for optimal performance.
                </div>
      </section>

            <!-- MLflow -->
            <section id="mlflow" class="section">
                <h2>MLflow Integration</h2>

                <p>Track experiments, compare models, and manage artifacts with MLflow.</p>

                <h3>Enable MLflow</h3>
                <p>Add to your configuration:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">YAML</span>
                    </div>
                    <pre><code>embedding:
  log_to_mlflow: true
  mlflow_tracking_uri: file:///path/to/mlruns
  mlflow_experiment: my-experiment
  mlflow_run_name: embedding-v1</code></pre>
                </div>

                <h3>View Experiments</h3>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">Command</span>
                    </div>
                    <pre><code>mlflow ui --backend-store-uri target/mlruns</code></pre>
                </div>
                <p>Open <code>http://localhost:5000</code> in your browser.</p>

                <h3>Logged Information</h3>
                <ul>
                    <li><strong>Parameters:</strong> All hyperparameters from config</li>
                    <li><strong>Metrics:</strong> Training/validation loss, F1, cosine similarity, etc.</li>
                    <li><strong>Artifacts:</strong> Model checkpoints, ONNX exports, configs</li>
                    <li><strong>System Metrics:</strong> GPU utilization, memory usage</li>
        </ul>

                <h3>Remote Tracking</h3>
                <p>Use a remote MLflow server:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">YAML</span>
                    </div>
                    <pre><code>embedding:
  mlflow_tracking_uri: https://mlflow.example.com</code></pre>
        </div>
      </section>

            <!-- Optimization -->
            <section id="optimization" class="section">
                <h2>Optimization</h2>

                <h3>Training Performance</h3>
                
                <h4>Use Mixed Precision</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">YAML</span>
      </div>
                    <pre><code>embedding:
  precision: bf16  # or fp16</code></pre>
                </div>
                <p><strong>Benefits:</strong> 2-3x faster training, 50% less memory</p>

                <h4>Gradient Accumulation</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">YAML</span>
                    </div>
                    <pre><code>embedding:
  batch_size: 8
  gradient_accumulation: 4  # Effective batch size: 32</code></pre>
                </div>
                <p><strong>Use case:</strong> Large effective batch sizes on limited GPU memory</p>

                <h4>Profile Training</h4>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">YAML</span>
                    </div>
                    <pre><code>embedding:
  profile_steps: 10</code></pre>
                </div>
                <p>View traces with <code>chrome://tracing</code></p>

                <h3>Inference Optimization</h3>
                
                <p>Sphana Trainer automatically optimizes models for inference:</p>
                <ul>
                    <li><strong>ONNX Export:</strong> Platform-independent format optimized for inference</li>
                    <li><strong>INT8 Quantization:</strong> ~4x smaller models, minimal accuracy loss</li>
                    <li><strong>Dynamic Axes:</strong> Support variable-length inputs efficiently</li>
        </ul>

                <h3>Quality Thresholds</h3>
                <p>Prevent poor models from being exported:</p>
                <div class="code-block">
                    <div class="code-header">
                        <span class="code-label">YAML</span>
                    </div>
                    <pre><code>embedding:
  metric_threshold: 0.8  # Minimum cosine similarity

relation:
  metric_threshold: 0.75  # Minimum macro F1

gnn:
  metric_threshold: 0.5  # Maximum validation loss</code></pre>
                </div>
      </section>

            <!-- Footer -->
            <footer class="footer">
                <div class="footer-content">
                    <p>Sphana Trainer ¬∑ Neural RAG Database Training CLI</p>
                    <p class="footer-links">
                        <a href="https://github.com/yourusername/sphana">GitHub</a> ¬∑
                        <a href="#overview">Documentation</a> ¬∑
                        <a href="mailto:support@example.com">Support</a>
                    </p>
      </div>
            </footer>
    </main>
  </div>

    <script src="script.js"></script>
  </body>
</html>
