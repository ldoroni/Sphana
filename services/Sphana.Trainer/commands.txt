# Navigate to project directory
cd services/Sphana.Trainer
$env:PYTHONPATH="src"

# Create VENV and install dependencies (output .venv/)
python -m venv .venv
.\.venv\Scripts\activate
python -m pip install --upgrade pip
pip install -r requirements.txt

# Download training data from wiki (output samples/wiki-docs/large/docs.jsonl)
python -m sphana_trainer.cli dataset-download-wiki `
    --titles-dir samples\wiki-titles\large\ `
    --full-content `
    --output-mode jsonl-per-domain `
    --output samples\wiki-docs\large\ `
    --compress `
    --limit 500000

# Install Stanza model, used by the 'ingest' command (one-time, ~250 MB)
python -m sphana_trainer.cli ingest-cache-models `
    --stanza-lang en

# Prepare training data for the train (output target/ingest/)
# In the relations output, "predicate" can have 3 values:
# - "entailment": The relation is a strong positive connection.
# - "contradiction": The entities are in opposition.
# - "neutral": The relationship is weak, unclear, or simply co-occurrence.
python -m sphana_trainer.cli ingest --config configs/ingest/wiki.yaml

# Build dataset from ingest (output target/datasets/)
python -m sphana_trainer.cli dataset-build-from-ingest --config configs/dataset-build/wiki.yaml

# Train models (output target/artifacts/)
python -m sphana_trainer.cli train embedding --config configs/embedding/wiki.yaml
python -m sphana_trainer.cli train relation --config configs/relation/wiki.yaml
python -m sphana_trainer.cli train gnn --config configs/gnn/wiki.yaml
python -m sphana_trainer.cli train ner --config configs/ner/base.yaml
python -m sphana_trainer.cli train llm --config configs/llm/base.yaml

# [OPTIONAL] Export models as ONNX (output target/manifests/latest.json)
python -m sphana_trainer.cli export --config configs/export/wiki.yaml

# [OPTIONAL] Package ONNX models (output target/manifests/latest.tar.gz)
python -m sphana_trainer.cli package --config configs/export/wiki.yaml
